# Copyright 2021 Yahoo, Licensed under the terms of the Apache License, Version 2.0.
# See LICENSE file in project root for terms.

DATASET:
  CLASS_WEIGHTS: null
  CROSS_MODAL:
    SOURCE: title
  DPA_ATTRIBUTES:
    DELETE_TERMS: null
    USE_CATEGORY: false
  IMAGE_DIR: null
  NAME: imat_fashion
  NUM_CLASSES: null
  PATH: /disk/datasets/imat2018/
  REQUIRE_IMAGES: false
  SINGLE_CLASS_BATCHES: false
DATA_LOADER:
  LOADER_NUM_WORKERS: 0
EXP_NAME: imat_queries_maaf
MODEL:
  COMPOSITION: maaf
  DEVICE: cuda
  DROPOUT_RATE: 0.1
  EMBED_DIM: 512  # consider switching to 1024
  IMAGE_MODEL:
    ARCHITECTURE: resnet50
    FREEZE_WEIGHTS: false
    OUTPUTS:
    - 3  # consider removing
    - 4
    PRETRAINED: true
    WEIGHTS: null
  LOSS: batch_based_classification  # consider double_softmax
  MAAF:
    ATTENTION_HEADS: 8
    ATTN_SOFTMAX_REPLACEMENT: null
    BLOCK_WIDTH: 256
    NUM_BLOCKS: 2
    OUTPUT: rwpool
    POSITION_ENCODING: null
  TEXT_MODEL:
    ARCHITECTURE: roberta
    EMBED_DIM: 512  # consider 1024?
    FREEZE_WEIGHTS: false
    MAX_TOKENS: 128
    MAX_VOCAB: 52000
    OUTPUT_RELU: false
    TOKENIZER: bpe
    TOKENIZER_PATH: roberta-base
    VOCAB_DATA: null
    VOCAB_MIN_FREQ: 0
  WEIGHTS: null
OUTPUT_DIR: /mnt/hff_vision_b/edodds/experiments/imat/
SOLVER:
  ALWAYS_EVAL_TEST: false
  BATCH_SIZE: 32  # consider 128
  DROP_WORST_RATE: 0
  EVAL_EVERY: 3
  FINAL_EVAL_ON_TEST: false
  LEARNING_RATE: 0.01
  LEARNING_RATE_DECAY: 0.1
  LEARNING_RATE_DECAY_FREQUENCY: 50000
  LR_DECAY_ONLY_ONCE: false
  NUM_ITERS: 150000  # consider matching epochs with clip-based experiments
  PRETRAINED_WEIGHT_LR_FACTOR_IMAGE: 0.1
  PRETRAINED_WEIGHT_LR_FACTOR_TEXT: 0.1
  SAVE_EVERY: 100
  SCHEDULE_ITERS: ''
  SCHEDULE_RATES: ''
  SOFTMAX_MARGIN: 0
  WEIGHT_DECAY: 1.0e-06
